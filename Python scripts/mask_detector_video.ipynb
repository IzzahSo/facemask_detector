{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mask_detector_video.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14kLrDfgtZguP42-k3Vs9nXmbI_IW_PQV","authorship_tag":"ABX9TyNKtyfCfkaHzzFOA89XYE56"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PHD59stI1EVC"},"source":["The only differences when it comes to imports is that they need a *VideoStream* class and *time* which help in working with real-time video streams.\n","\n","In addition, *imutils* is used for its aspect-aware resizing method."]},{"cell_type":"code","metadata":{"id":"ccumxPjwmysS"},"source":["# import the necessary packages\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.models import load_model\n","from imutils.video import VideoStream\n","import argparse\n","import numpy as np\n","import imutils\n","import time\n","import cv2\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_QdjFfDI0nT6"},"source":["The detect_and_predict_mask's algorithm for this script is similar to the detect_mask_image, however t is pieced together in such a way to allow for processing every frame of the webcam stream.\n","\n","This function allows our frame processing loop easier to read.\n","First it detects faces and then applies our face mask classifier to each face ROI.\n","\n","Inside the *detections* loop, the weak detections are filtered out and bounding box is extracting while ensuring their coordinates do not fall outside the bounds of the image.\n","\n","Later, the face ROIs are added to the two corresponding list which then have been pre-processed and append the face ROIs and bounding boxed to respective lists.\n"]},{"cell_type":"code","metadata":{"id":"otMNcTJHDmSD","executionInfo":{"status":"ok","timestamp":1622320340264,"user_tz":-480,"elapsed":375,"user":{"displayName":"IzzahSo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbS6btI35Xt7vsVYIOlZxZFUjNPf7yR1my07jNgg=s64","userId":"13559840588960174987"}}},"source":["def detect_and_predict_mask(frame,faceNet,maskNet):\n","    #grab the dimensions of the frame and then construct a blob\n","    if np.shape(frame) != ():\n","      (h,w)=frame.shape[:2]\n","    blob=cv2.dnn.blobFromImage(frame,1.0,(300,300),(104.0,177.0,123.0))\n","    \n","    faceNet.setInput(blob)\n","    detections=faceNet.forward()\n","    \n","    #initialize our list of faces, their corresponding locations and list of predictions\n","    \n","    faces=[]\n","    locs=[]\n","    preds=[]\n","    \n","    \n","    for i in range(0,detections.shape[2]):\n","        confidence=detections[0,0,i,2]\n","    \n","    \n","        if confidence>0.5:\n","        #we need the X,Y coordinates\n","            box=detections[0,0,i,3:7]*np.array([w,h,w,h])\n","            (startX,startY,endX,endY)=box.astype('int')\n","        \n","            #ensure the bounding boxes fall within the dimensions of the frame\n","            (startX,startY)=(max(0,startX),max(0,startY))\n","            (endX,endY)=(min(w-1,endX), min(h-1,endY))\n","        \n","            #extract the face ROI, convert it from BGR to RGB channel, resize it to 224,224 and preprocess it\n","            face=frame[startY:endY, startX:endX]\n","            face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n","            face=cv2.resize(face,(224,224))\n","            face=img_to_array(face)\n","            face=preprocess_input(face)\n","        \n","            faces.append(face)\n","            locs.append((startX,startY,endX,endY))\n","        \n","        #only make a predictions if atleast one face was detected\n","        if len(faces)>0:\n","            faces=np.array(faces,dtype='float32')\n","            preds=maskNet.predict(faces,batch_size=12)\n","        \n","        return (locs,preds)\n","        "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsuIcTlgx9X5"},"source":["# construct the argument parser and parse the arguments\n","# ap = argparse.ArgumentParser()\n","# ap.add_argument(\"-f\", \"--face\", type=str,\n","# \tdefault=\"facemask_detector\",\n","# \thelp=\"path to face detector model directory\")\n","# ap.add_argument(\"-m\", \"--model\", type=str,\n","# \tdefault=\"mask_detector.model\",\n","# \thelp=\"path to trained face mask detector model\")\n","# ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n","# \thelp=\"minimum probability to filter weak detections\")\n","# args = vars(ap.parse_args())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpCnjjAzF7qT"},"source":["prototxtPath = os.path.sep.join([r'/content/drive/MyDrive/facemask_detector', 'deploy.prototxt'])\n","weightsPath = os.path.sep.join([r'/content/drive/MyDrive/facemask_detector', 'res10_300x300_ssd_iter_140000.caffemodel'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrdc6QLXGHp0"},"source":["faceNet=cv2.dnn.readNet(prototxtPath,weightsPath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfRVZHHVGPFB"},"source":["maskNet = load_model(r'/content/drive/MyDrive/facemask_detector/mobilenet_v2.model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Y1L5WkPHZ7e"},"source":["vs=VideoStream(src=0).start()\n","time.sleep(2.0)\n","\n","while True:\n","    #grab the frame from the threaded video stream and resize it\n","    #to have a maximum width of 400 pixels\n","    frame=vs.read()\n","    frame=imutils.resize(frame,width=400)\n","    \n","    #detect faces in the frame and preict if they are waring masks or not\n","    (locs,preds)=detect_and_predict_mask(frame,faceNet,maskNet)\n","    \n","    #loop over the detected face locations and their corrosponding loactions\n","    \n","    for (box,pred) in zip(locs,preds):\n","        (startX,startY,endX,endY)=box\n","        (mask,withoutMask)=pred\n","        \n","        #determine the class label and color we will use to draw the bounding box and text\n","        label='Mask' if mask>withoutMask else 'No Mask'\n","        color=(0,255,0) if label=='Mask' else (0,0,255)\n","        \n","        #display the label and bounding boxes\n","        cv2.putText(frame,label,(startX,startY-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,color,2)\n","        \n","        cv2.rectangle(frame,(startX,startY),(endX,endY),color,2)\n","        \n","    #show the output frame\n","    cv2.imshow(\"Frame\",frame)\n","    key=cv2.waitKey(1) & 0xFF\n","    \n","    if key==ord('q'):\n","        break\n","        \n","cv2.destroyAllWindows()\n","vs.stop()"],"execution_count":null,"outputs":[]}]}